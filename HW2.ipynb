{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Самостоятельно разобраться с тем, что такое tfidf (документация https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html и еще - https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
    "2. Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)\n",
    "3. Повторить п.2, но используя уже не медиану, а max\n",
    "4. (опциональное, если очень хочется) Воспользовавшись полученными знаниями из п.1, повторить пункт 2, но уже взвешивая новости по tfidf (подсказка: нужно получить веса-коэффициенты для каждого документа. Не все документы одинаково информативны и несут какой-то положительный сигнал). Подсказка 2 - нужен именно idf, как вес.\n",
    "5. Сформировать на выходе единую таблицу, сравнивающую качество 3 разных метода получения эмбедингов пользователей: mean, median, max, idf_mean по метрикам roc_auc, precision, recall, f_score\n",
    "6. Сделать самостоятельные выводы и предположения о том, почему тот или ной способ оказался эффективнее остальных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задания 2-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import datapath\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title\n",
       "0       6  Заместитель председателяnправительства РФnСерг...\n",
       "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
       "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"C:/Users/yana/2/articles.csv\")\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(\"C:/Users/yana/2/users_articles.csv\")\n",
    "users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_ru = stopwords.words('russian')\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "with open('C:/Users/yana/2/stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "stopword_ru += additional_stopwords\n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "    \n",
    "    #tokens = list(tokenize(text))\n",
    "    #words = [_.text for _ in tokens]\n",
    "    #words = [w for w in words if w not in stopword_ru]\n",
    "    \n",
    "    #return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w)>1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru] # [6]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Possible nested set at position 39\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)\n",
    "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)\n",
    "texts = [t for t in news['title'].values]\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(common_corpus, num_topics=25, id2word=common_dictionary)#, passes=10\n",
    "temp_file = datapath(\"model.lda\")\n",
    "lda.save(temp_file)\n",
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: человек который сотрудник обнаружить район тело nn\n",
      "topic_1: спутник технология запуск поверхность российский система который\n",
      "topic_2: год млн компания цена суд руб который\n",
      "topic_3: год погибнуть человек который это миссия лечение\n",
      "topic_4: год планета достигать уголь рыба величина лауреат\n",
      "topic_5: фонд экономика это турист экономический который система\n",
      "topic_6: китай место японский рейтинг япония китайский бомба\n",
      "topic_7: научный исследование ракета это учёный год который\n",
      "topic_8: это россия который год мочь человек весь\n",
      "topic_9: исследователь журнал земля который рак авария ветер\n",
      "topic_10: год банк статья сша nn нефть страна\n",
      "topic_11: самолёт корабль солнечный сила российский территория войско\n",
      "topic_12: год учёный это который работа человек жизнь\n",
      "topic_13: это снижение квартира восток год который мочь\n",
      "topic_14: газ крым турция турецкий газпром астероид конкурс\n",
      "topic_15: луна год компания взрыв космический двигатель полёт\n",
      "topic_16: nn президент путин россия владимир nnn глава\n",
      "topic_17: год млрд проект страна рост эксперт который\n",
      "topic_18: мозг чёрный писать солнце организм алкоголь высота\n",
      "topic_19: станция день температура всё весь это время\n",
      "topic_20: военный это который армия свой граница мочь\n",
      "topic_21: nn фестиваль космонавт пройти стать первый км\n",
      "topic_22: год смерть ребёнок клетка налог который исследование\n",
      "topic_23: nn туроператор популярный подсчитать лётчик зонд порода\n",
      "topic_24: год завод который депутат объём сша федеральный\n"
     ]
    }
   ],
   "source": [
    "x=lda.show_topics(num_topics=25, num_words=7,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "#Below Code Prints Only Words \n",
    "for topic,words in topics_words:\n",
    "    print(\"topic_{}: \".format(topic)+\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_vector(text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "\n",
    "    output_vector = []\n",
    "    for i in range(25):\n",
    "        if i not in not_null_topics:\n",
    "            output_vector.append(0)\n",
    "        else:\n",
    "            output_vector.append(not_null_topics[i])\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.739258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133401</td>\n",
       "      <td>0.162524</td>\n",
       "      <td>0.179933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075691</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  topic_0   topic_1   topic_2  topic_3   topic_4  topic_5   topic_6  \\\n",
       "0       6      0.0  0.000000  0.000000      0.0  0.000000      0.0  0.027635   \n",
       "1    4896      0.0  0.000000  0.049017      0.0  0.000000      0.0  0.000000   \n",
       "2    4897      0.0  0.000000  0.388558      0.0  0.000000      0.0  0.000000   \n",
       "3    4898      0.0  0.000000  0.000000      0.0  0.000000      0.0  0.133401   \n",
       "4    4899      0.0  0.366926  0.000000      0.0  0.110014      0.0  0.000000   \n",
       "\n",
       "    topic_7   topic_8  ...  topic_15  topic_16  topic_17  topic_18  topic_19  \\\n",
       "0  0.000000  0.215384  ...  0.000000       0.0  0.000000       0.0  0.000000   \n",
       "1  0.187567  0.000000  ...  0.175966       0.0  0.000000       0.0  0.538640   \n",
       "2  0.000000  0.000000  ...  0.000000       0.0  0.000000       0.0  0.221419   \n",
       "3  0.162524  0.179933  ...  0.000000       0.0  0.000000       0.0  0.000000   \n",
       "4  0.100949  0.000000  ...  0.000000       0.0  0.365297       0.0  0.000000   \n",
       "\n",
       "   topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0       0.0  0.010949       0.0  0.000000  0.739258  \n",
       "1       0.0  0.000000       0.0  0.000000  0.000000  \n",
       "2       0.0  0.000000       0.0  0.000000  0.000000  \n",
       "3       0.0  0.000000       0.0  0.075691  0.000000  \n",
       "4       0.0  0.000000       0.0  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
    "topic_matrix.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(25)]]\n",
    "topic_matrix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(25)]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding(user_articles_list, method):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    if method=='mean':\n",
    "        user_vector = np.mean(user_vector, 0)\n",
    "    elif method=='median':\n",
    "        user_vector = np.median(user_vector, 0)\n",
    "    elif method == 'max':\n",
    "        user_vector = np.max(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим таблицу для записи результатов\n",
    "columns = ['Methods', 'F-Score', 'Precision', 'Recall', 'Roc_auc-score']\n",
    "table = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_process(x, metrics):\n",
    "    user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x, metrics), 1)])\n",
    "    user_embeddings.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "    user_embeddings['uid'] = users['uid'].values\n",
    "    user_embeddings = user_embeddings[['uid']+['topic_{}'.format(i) for i in range(25)]]\n",
    "    target = pd.read_csv(\"users_churn.csv\")\n",
    "    X = pd.merge(user_embeddings, target, 'left')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X['churn'], test_size=0.3, random_state=0)\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    preds = logreg.predict_proba(X_test)[:, 1]\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)\n",
    "    print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]), f'Roc_auc_score={roc_auc_score(y_test, preds):.3f}')\n",
    "    return fscore[ix], precision[ix], recall[ix],roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.255634, F-Score=0.695, Precision=0.619, Recall=0.792 Roc_auc_score=0.949\n",
      "Best Threshold=0.204646, F-Score=0.648, Precision=0.537, Recall=0.816 Roc_auc_score=0.938\n",
      "Best Threshold=0.294648, F-Score=0.776, Precision=0.713, Recall=0.850 Roc_auc_score=0.975\n"
     ]
    }
   ],
   "source": [
    "mean = embedding_process(x, 'mean')\n",
    "median = embedding_process(x, 'median')\n",
    "maximum = embedding_process(x, 'max')\n",
    "table.loc[len(table)] = ['Mean', mean[0], mean[1], mean[2], mean[3]]\n",
    "table.loc[len(table)] = ['Median', median[0], median[1], median[2], median[3]]\n",
    "table.loc[len(table)] = ['Max', maximum[0], maximum[1], maximum[2], maximum[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_vector(text):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=25)\n",
    "    vectorizer.fit_transform(text)\n",
    "\n",
    "    output_vector = []\n",
    "    for i in range(25):\n",
    "        if i < len(vectorizer.idf_):\n",
    "            output_vector.append(vectorizer.idf_[i])\n",
    "        else:\n",
    "            output_vector.append(0)\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>4.028522</td>\n",
       "      <td>4.721669</td>\n",
       "      <td>4.721669</td>\n",
       "      <td>5.127134</td>\n",
       "      <td>5.127134</td>\n",
       "      <td>4.210844</td>\n",
       "      <td>4.210844</td>\n",
       "      <td>4.433987</td>\n",
       "      <td>4.721669</td>\n",
       "      <td>...</td>\n",
       "      <td>5.127134</td>\n",
       "      <td>5.127134</td>\n",
       "      <td>5.127134</td>\n",
       "      <td>5.127134</td>\n",
       "      <td>4.433987</td>\n",
       "      <td>5.127134</td>\n",
       "      <td>5.127134</td>\n",
       "      <td>4.433987</td>\n",
       "      <td>4.433987</td>\n",
       "      <td>4.721669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>3.662588</td>\n",
       "      <td>3.662588</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>3.374906</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>...</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>3.662588</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>4.068053</td>\n",
       "      <td>4.068053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>3.772589</td>\n",
       "      <td>3.772589</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>...</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>4.178054</td>\n",
       "      <td>3.484907</td>\n",
       "      <td>4.178054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>4.390024</td>\n",
       "      <td>4.390024</td>\n",
       "      <td>4.390024</td>\n",
       "      <td>4.390024</td>\n",
       "      <td>4.390024</td>\n",
       "      <td>4.390024</td>\n",
       "      <td>4.795489</td>\n",
       "      <td>4.795489</td>\n",
       "      <td>4.795489</td>\n",
       "      <td>...</td>\n",
       "      <td>4.795489</td>\n",
       "      <td>4.795489</td>\n",
       "      <td>4.795489</td>\n",
       "      <td>4.795489</td>\n",
       "      <td>4.795489</td>\n",
       "      <td>4.795489</td>\n",
       "      <td>4.795489</td>\n",
       "      <td>4.795489</td>\n",
       "      <td>4.795489</td>\n",
       "      <td>4.390024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.564949</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>...</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.277267</td>\n",
       "      <td>3.564949</td>\n",
       "      <td>3.970414</td>\n",
       "      <td>3.970414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id   topic_0   topic_1   topic_2   topic_3   topic_4   topic_5  \\\n",
       "0       6  4.028522  4.721669  4.721669  5.127134  5.127134  4.210844   \n",
       "1    4896  3.662588  3.662588  4.068053  4.068053  3.374906  4.068053   \n",
       "2    4897  4.178054  4.178054  4.178054  3.772589  3.772589  4.178054   \n",
       "3    4898  4.390024  4.390024  4.390024  4.390024  4.390024  4.390024   \n",
       "4    4899  3.970414  3.970414  3.970414  3.970414  3.970414  3.564949   \n",
       "\n",
       "    topic_6   topic_7   topic_8  ...  topic_15  topic_16  topic_17  topic_18  \\\n",
       "0  4.210844  4.433987  4.721669  ...  5.127134  5.127134  5.127134  5.127134   \n",
       "1  4.068053  4.068053  4.068053  ...  4.068053  4.068053  4.068053  4.068053   \n",
       "2  4.178054  4.178054  4.178054  ...  4.178054  4.178054  4.178054  4.178054   \n",
       "3  4.795489  4.795489  4.795489  ...  4.795489  4.795489  4.795489  4.795489   \n",
       "4  3.970414  3.970414  3.970414  ...  3.970414  3.970414  3.970414  3.970414   \n",
       "\n",
       "   topic_19  topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0  4.433987  5.127134  5.127134  4.433987  4.433987  4.721669  \n",
       "1  4.068053  3.662588  4.068053  4.068053  4.068053  4.068053  \n",
       "2  4.178054  4.178054  4.178054  4.178054  3.484907  4.178054  \n",
       "3  4.795489  4.795489  4.795489  4.795489  4.795489  4.390024  \n",
       "4  3.970414  3.970414  3.277267  3.564949  3.970414  3.970414  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_tfidf_vector(text) for text in news['title'].values])\n",
    "topic_matrix.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(25)]]\n",
    "topic_matrix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(25)]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.650527, F-Score=0.998, Precision=0.997, Recall=1.000 Roc_auc_score=1.000\n",
      "Best Threshold=0.955627, F-Score=1.000, Precision=1.000, Recall=1.000 Roc_auc_score=1.000\n",
      "Best Threshold=0.212619, F-Score=0.789, Precision=0.671, Recall=0.959 Roc_auc_score=0.975\n"
     ]
    }
   ],
   "source": [
    "tfidf_mean = embedding_process(x, 'mean')\n",
    "tfidf_median = embedding_process(x, 'median')\n",
    "tfidf_maximum = embedding_process(x, 'max')\n",
    "table.loc[len(table)] = ['TFIDF_Mean', tfidf_mean[0], tfidf_mean[1], tfidf_mean[2], tfidf_mean[3]]\n",
    "table.loc[len(table)] = ['TFIDF_Median', tfidf_median[0], tfidf_median[1], tfidf_median[2], tfidf_median[3]]\n",
    "table.loc[len(table)] = ['TFIDF_Max', tfidf_maximum[0], tfidf_maximum[1], tfidf_maximum[2], tfidf_maximum[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Roc_auc-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.694611</td>\n",
       "      <td>0.618667</td>\n",
       "      <td>0.791809</td>\n",
       "      <td>0.949332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Median</td>\n",
       "      <td>0.647696</td>\n",
       "      <td>0.537079</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>0.937535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Max</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.974575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TFIDF_Mean</td>\n",
       "      <td>0.998296</td>\n",
       "      <td>0.996599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TFIDF_Median</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TFIDF_Max</td>\n",
       "      <td>0.789326</td>\n",
       "      <td>0.670644</td>\n",
       "      <td>0.959044</td>\n",
       "      <td>0.974873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Methods   F-Score  Precision    Recall  Roc_auc-score\n",
       "0          Mean  0.694611   0.618667  0.791809       0.949332\n",
       "1        Median  0.647696   0.537079  0.815700       0.937535\n",
       "2           Max  0.775701   0.713467  0.849829       0.974575\n",
       "3    TFIDF_Mean  0.998296   0.996599  1.000000       0.999998\n",
       "4  TFIDF_Median  1.000000   1.000000  1.000000       1.000000\n",
       "5     TFIDF_Max  0.789326   0.670644  0.959044       0.974873"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При различных вариантах разбиения датасета лучшие результаты были у различных способов (без tfidf). Наиболее очевидным и стабильным методом кажется медиана, т.к. она менее чувствительна к выбросам. Но, к примеру, при последнем запуске она показала наихудший результат. Модель tfidf показывает более высокие результаты, т.к. выявляет наиболее информативные документы. С медианой дает идеальные результаты 1.0 по всем метрикам, что подозрительно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
